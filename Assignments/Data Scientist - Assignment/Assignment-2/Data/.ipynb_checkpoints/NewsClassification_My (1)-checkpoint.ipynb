{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Text Classification Model - Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\singhxyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from itertools import islice\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                Desc  \n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...  \n",
       "1  Reuters - Private investment firm Carlyle Grou...  \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...  \n",
       "3  Reuters - Authorities have halted oil export\\f...  \n",
       "4  AFP - Tearaway world oil prices, toppling reco...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n",
    "os.chdir('C:\\\\Amazon\\\\Learning\\\\Analytics Path_Py\\\\Text Mining')\n",
    "os.getcwd()\n",
    "df=pd.read_csv('train.csv', header=None)\n",
    "df.head()\n",
    "df.columns = ['Class','ShortDesc', 'Desc']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stops = stopwords.words('english')\n",
    "ad_stopwords = ['monkey', 'like','com','use','help','create','time','want','a','about','above','across','after','afterwards']\n",
    "stops.extend(ad_stopwords)\n",
    "stops[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"b'Ram\", 'friend.', \"company'\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\singhxyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "noise_free_words=['']\n",
    "d=['']\n",
    "def remove_noise(input_text):\n",
    "    input_text = str(input_text).encode('ascii','ignore') ## this is putting a 'b' in the start of a sentence. Don't know why\n",
    "    input_text = str(input_text).replace(',',\"\")\n",
    "    words = str(input_text).split()  ##  splitting into words\n",
    "    #print('words are: ', words)\n",
    "    pos_words = nltk.pos_tag(words)\n",
    "    #print('Post of tags are: ', pos_words)\n",
    "    noise_free_words = [i[0] for i in pos_words if i[1] in ('NN')] ## NN means common noun\n",
    "    niose_free_words = [w for w in noise_free_words if w.lower() not in stops]\n",
    "    return noise_free_words\n",
    "\n",
    "## Testing of above function\n",
    "input_text = 'Ram was always my best friend. Google is best company'\n",
    "f=remove_noise(input_text)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>[dwindling\\\\band, again.\"]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>[investment, firm, reputation, defense, indust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>[crude, economy, outlook, stock, market, week,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>[oil, pipeline, after\\\\intelligence, militia, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>[world, oil, toppling, menace, elections.']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                             cleaned  \n",
       "0                         [dwindling\\\\band, again.\"]  \n",
       "1  [investment, firm, reputation, defense, indust...  \n",
       "2  [crude, economy, outlook, stock, market, week,...  \n",
       "3  [oil, pipeline, after\\\\intelligence, militia, ...  \n",
       "4        [world, oil, toppling, menace, elections.']  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned']= df.Desc.apply(remove_noise)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\singhxyp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
       "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
       "      <td>[dwindling\\\\band, again.\"]</td>\n",
       "      <td>dwindling\\\\band again.\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
       "      <td>[investment, firm, reputation, defense, indust...</td>\n",
       "      <td>investment firm reputation defense industry pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
       "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
       "      <td>[crude, economy, outlook, stock, market, week,...</td>\n",
       "      <td>crude economy outlook stock market week depth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
       "      <td>[oil, pipeline, after\\\\intelligence, militia, ...</td>\n",
       "      <td>oil pipeline after\\\\intelligence militia oil o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
       "      <td>[world, oil, toppling, menace, elections.']</td>\n",
       "      <td>world oil toppling menace elections.'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
       "1      3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
       "2      3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
       "3      3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
       "4      3  Oil prices soar to all-time record, posing new...   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Reuters - Short-sellers, Wall Street's dwindli...   \n",
       "1  Reuters - Private investment firm Carlyle Grou...   \n",
       "2  Reuters - Soaring crude prices plus worries\\ab...   \n",
       "3  Reuters - Authorities have halted oil export\\f...   \n",
       "4  AFP - Tearaway world oil prices, toppling reco...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0                         [dwindling\\\\band, again.\"]   \n",
       "1  [investment, firm, reputation, defense, indust...   \n",
       "2  [crude, economy, outlook, stock, market, week,...   \n",
       "3  [oil, pipeline, after\\\\intelligence, militia, ...   \n",
       "4        [world, oil, toppling, menace, elections.']   \n",
       "\n",
       "                                             stemmed  \n",
       "0                            dwindling\\\\band again.\"  \n",
       "1  investment firm reputation defense industry pa...  \n",
       "2  crude economy outlook stock market week depth ...  \n",
       "3  oil pipeline after\\\\intelligence militia oil o...  \n",
       "4              world oil toppling menace elections.'  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##try the lemmatizer on data. WE will use WordNetLemmatizer\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer= WordNetLemmatizer()\n",
    "df['stemmed'] = df.cleaned.map(lambda x: ' '.join([lemmatizer.lemmatize(y) for y in x]))\n",
    "df.stemmed.head()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words=stops, min_df=1, max_df=0.5, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dwindling', 89973),\n",
       " ('band', 22445),\n",
       " ('dwindling band', 89974),\n",
       " ('investment', 144677),\n",
       " ('firm', 107421),\n",
       " ('reputation', 237710),\n",
       " ('defense', 78470),\n",
       " ('industry', 139471),\n",
       " ('part', 200522),\n",
       " ('market', 167440),\n",
       " ('investment firm', 144748),\n",
       " ('firm reputation', 107793),\n",
       " ('reputation defense', 237726),\n",
       " ('defense industry', 78585),\n",
       " ('industry part', 139834),\n",
       " ('part market', 200826),\n",
       " ('crude', 71272),\n",
       " ('economy', 90776),\n",
       " ('outlook', 197146),\n",
       " ('stock', 275616)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import islice\n",
    "cvec.fit(df.stemmed) ## count vectorizer simply gives teh count of words. \n",
    "                     ## It will have all the words from stemmed data and their frequency count in each document\n",
    "list(islice(cvec.vocabulary_.items(),20))  ## will give top 20 words(appearing highest number of times) from cvec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "328336"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cvec.vocabulary_) ## total words in cvec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## In Above case we have taken all the words by providing min_df=1 which means even if a word is \n",
    "## present only once it has taken it into consideration\n",
    "\n",
    "## We can reduce this and take only meaningful words by providing some value of min_df e.g. 0.001 i.e. a word should be present\n",
    "## at least in 1% of teh documents\n",
    "\n",
    "cvec = CountVectorizer(stop_words=stops, min_df = 0.001, max_df = 0.9, ngram_range=(1,2))\n",
    "cvec.fit(df.stemmed)\n",
    "len(cvec.vocabulary_) ## So we see now we have picked up 1100 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (120000, 1098)\n",
      "nonzero count: 491543\n",
      "sparsity: 0.37%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts = cvec.transform(df.stemmed)\n",
    "print('sparse matrix shape:', cvec_counts.shape)\n",
    "print('nonzero count:' , cvec_counts.nnz)\n",
    "print('sparsity: %.2f%%' %(100.0 * cvec_counts.nnz/(cvec_counts.shape[0] * cvec_counts.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<120000x1098 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 491543 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we can either use countvectorizer and tfidftransformer combination or tfidfvectorized alone\n",
    "## Here we will use the tfidftransformer ov countvectorizer\n",
    "\n",
    "transformer =TfidfTransformer()\n",
    "transformed_weights = transformer.fit_transform(cvec_counts)\n",
    "transformed_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>company</td>\n",
       "      <td>0.017661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>yesterday</td>\n",
       "      <td>0.016329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>year</td>\n",
       "      <td>0.015628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068</th>\n",
       "      <td>week</td>\n",
       "      <td>0.013734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>quot</td>\n",
       "      <td>0.013158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1085</th>\n",
       "      <td>world</td>\n",
       "      <td>0.013009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>today</td>\n",
       "      <td>0.012786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>government</td>\n",
       "      <td>0.012462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>night</td>\n",
       "      <td>0.012041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>game</td>\n",
       "      <td>0.012005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>oil</td>\n",
       "      <td>0.011647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>season</td>\n",
       "      <td>0.011220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>team</td>\n",
       "      <td>0.010703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>victory</td>\n",
       "      <td>0.010282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>software</td>\n",
       "      <td>0.010029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>678</th>\n",
       "      <td>percent</td>\n",
       "      <td>0.009635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>security</td>\n",
       "      <td>0.009086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>day</td>\n",
       "      <td>0.008870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>country</td>\n",
       "      <td>0.008669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>market</td>\n",
       "      <td>0.008535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            term    weight\n",
       "197      company  0.017661\n",
       "1095   yesterday  0.016329\n",
       "1092        year  0.015628\n",
       "1068        week  0.013734\n",
       "764         quot  0.013158\n",
       "1085       world  0.013009\n",
       "993        today  0.012786\n",
       "404   government  0.012462\n",
       "616        night  0.012041\n",
       "391         game  0.012005\n",
       "628          oil  0.011647\n",
       "844       season  0.011220\n",
       "974         team  0.010703\n",
       "1044     victory  0.010282\n",
       "882     software  0.010029\n",
       "678      percent  0.009635\n",
       "849     security  0.009086\n",
       "249          day  0.008870\n",
       "225      country  0.008669\n",
       "550       market  0.008535"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = np.asarray(transformed_weights.mean(axis=0)).ravel().tolist()\n",
    "weights_df=pd.DataFrame({'term':cvec.get_feature_names(), 'weight':weights}) # will provide the transformed weights of each term\n",
    "weights_df.sort_values(by='weight', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Now we will try Naive Bayes on this cleaned data(transformed weights). We are passing meaningful words to train the model\n",
    "\n",
    "target=df['Class']\n",
    "nb=MultinomialNB()\n",
    "nb.fit(transformed_weights, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3                  Fears for T N pension after talks   \n",
       "1      4  The Race is On: Second Private Team Sets Launc...   \n",
       "2      4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                                Desc  \n",
       "0  Unions representing workers at Turner   Newall...  \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
       "2  AP - A company founded by a chemistry research...  \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...  \n",
       "4  AP - Southern California's smog-fighting agenc...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## repeat the same process on test data\n",
    "\n",
    "df1=pd.read_csv('test.csv', header=None)\n",
    "df1.columns = ['Class', 'ShortDesc','Desc']\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>[parent, firm]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>[second\\\\team, contest, space, flight, first\\\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>[company, chemistry, researcher, grant, method...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>[dawn, shift, blur, day]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>[smog-fighting, agency, variety, nation's, air...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Open Letter Against British Copyright Indoctri...</td>\n",
       "      <td>The British Department for Education and Skill...</td>\n",
       "      <td>[campaign, intention, generation, music, indus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4</td>\n",
       "      <td>Loosing the War on Terrorism</td>\n",
       "      <td>\\\\\"Sven Jaschan, self-confessed author of the ...</td>\n",
       "      <td>[author, percent, virus, roundup, company, cus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>FOAFKey: FOAF, PGP, Key Distribution, and Bloo...</td>\n",
       "      <td>\\\\FOAF/LOAF  and bloom filters have a lot of i...</td>\n",
       "      <td>[b'\\\\\\\\FOAF/LOAF, bloom, lot, social\\\\network,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>E-mail scam targets police chief</td>\n",
       "      <td>Wiltshire Police warns about \"phishing\" after ...</td>\n",
       "      <td>[b'Wiltshire, \"phishing\", fraud, squad, chief,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4</td>\n",
       "      <td>Card fraud unit nets 36,000 cards</td>\n",
       "      <td>In its first two years, the UK's dedicated car...</td>\n",
       "      <td>[card, fraud, unit]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3                  Fears for T N pension after talks   \n",
       "1      4  The Race is On: Second Private Team Sets Launc...   \n",
       "2      4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "5      4  Open Letter Against British Copyright Indoctri...   \n",
       "6      4                       Loosing the War on Terrorism   \n",
       "7      4  FOAFKey: FOAF, PGP, Key Distribution, and Bloo...   \n",
       "8      4                   E-mail scam targets police chief   \n",
       "9      4                  Card fraud unit nets 36,000 cards   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Unions representing workers at Turner   Newall...   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   \n",
       "2  AP - A company founded by a chemistry research...   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   \n",
       "4  AP - Southern California's smog-fighting agenc...   \n",
       "5  The British Department for Education and Skill...   \n",
       "6  \\\\\"Sven Jaschan, self-confessed author of the ...   \n",
       "7  \\\\FOAF/LOAF  and bloom filters have a lot of i...   \n",
       "8  Wiltshire Police warns about \"phishing\" after ...   \n",
       "9  In its first two years, the UK's dedicated car...   \n",
       "\n",
       "                                             Cleaned  \n",
       "0                                     [parent, firm]  \n",
       "1  [second\\\\team, contest, space, flight, first\\\\...  \n",
       "2  [company, chemistry, researcher, grant, method...  \n",
       "3                           [dawn, shift, blur, day]  \n",
       "4  [smog-fighting, agency, variety, nation's, air...  \n",
       "5  [campaign, intention, generation, music, indus...  \n",
       "6  [author, percent, virus, roundup, company, cus...  \n",
       "7  [b'\\\\\\\\FOAF/LOAF, bloom, lot, social\\\\network,...  \n",
       "8  [b'Wiltshire, \"phishing\", fraud, squad, chief,...  \n",
       "9                                [card, fraud, unit]  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['Cleaned'] = df1.Desc.apply(remove_noise)\n",
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>ShortDesc</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Cleaned</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>Fears for T N pension after talks</td>\n",
       "      <td>Unions representing workers at Turner   Newall...</td>\n",
       "      <td>[parent, firm]</td>\n",
       "      <td>parent firm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
       "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
       "      <td>[second\\\\team, contest, space, flight, first\\\\...</td>\n",
       "      <td>second\\\\team contest space flight first\\\\launc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
       "      <td>AP - A company founded by a chemistry research...</td>\n",
       "      <td>[company, chemistry, researcher, grant, method...</td>\n",
       "      <td>company chemistry researcher grant method amin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
       "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
       "      <td>[dawn, shift, blur, day]</td>\n",
       "      <td>dawn shift blur day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
       "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
       "      <td>[smog-fighting, agency, variety, nation's, air...</td>\n",
       "      <td>smog-fighting agency variety nation's air poll...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class                                          ShortDesc  \\\n",
       "0      3                  Fears for T N pension after talks   \n",
       "1      4  The Race is On: Second Private Team Sets Launc...   \n",
       "2      4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
       "3      4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
       "4      4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
       "\n",
       "                                                Desc  \\\n",
       "0  Unions representing workers at Turner   Newall...   \n",
       "1  SPACE.com - TORONTO, Canada -- A second\\team o...   \n",
       "2  AP - A company founded by a chemistry research...   \n",
       "3  AP - It's barely dawn when Mike Fitzpatrick st...   \n",
       "4  AP - Southern California's smog-fighting agenc...   \n",
       "\n",
       "                                             Cleaned  \\\n",
       "0                                     [parent, firm]   \n",
       "1  [second\\\\team, contest, space, flight, first\\\\...   \n",
       "2  [company, chemistry, researcher, grant, method...   \n",
       "3                           [dawn, shift, blur, day]   \n",
       "4  [smog-fighting, agency, variety, nation's, air...   \n",
       "\n",
       "                                             stemmed  \n",
       "0                                        parent firm  \n",
       "1  second\\\\team contest space flight first\\\\launc...  \n",
       "2  company chemistry researcher grant method amin...  \n",
       "3                                dawn shift blur day  \n",
       "4  smog-fighting agency variety nation's air poll...  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer= WordNetLemmatizer()\n",
    "df1['stemmed'] = df1.Cleaned.map(lambda x: ' '.join([lemmatizer.lemmatize(y) for y in x]))\n",
    "df1.stemmed.head()\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec1 = CountVectorizer(stop_words=stops, min_df=0.0011, max_df=0.9, ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('parent', 623),\n",
       " ('firm', 346),\n",
       " ('second', 796),\n",
       " ('team', 917),\n",
       " ('contest', 205),\n",
       " ('space', 843),\n",
       " ('flight', 348),\n",
       " ('launch', 472),\n",
       " ('date', 237),\n",
       " ('rocket', 768),\n",
       " ('company', 190),\n",
       " ('building', 113),\n",
       " ('day', 238),\n",
       " ('fighting', 339),\n",
       " ('agency', 19),\n",
       " ('nation', 565),\n",
       " ('air', 24),\n",
       " ('campaign', 123),\n",
       " ('generation', 377),\n",
       " ('music', 562)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec1.fit(df1.stemmed) # this fit we are using only to analyze the data. WE don't need to fit test data\n",
    "list(islice(cvec1.vocabulary_.items(),20)) ##will gve 20 random terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1176"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvec1 = CountVectorizer(stop_words=stops, min_df=.001, max_df=.8, ngram_range=(1,2))\n",
    "cvec1.fit(df1.stemmed)\n",
    "len(cvec1.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparse matrix shape: (7600, 1098)\n",
      "nonzero count: 30709\n",
      "sparsity: 0.37%\n"
     ]
    }
   ],
   "source": [
    "cvec_counts1 = cvec.transform(df1.stemmed)  ## Here note that we are using the same count vectorizer which we used to train \n",
    "                                            ## the data. We are transforming the test data . Make sure we are not fitting it\n",
    "print ('sparse matrix shape:', cvec_counts1.shape)\n",
    "print ('nonzero count:', cvec_counts1.nnz)\n",
    "print ('sparsity: %.2f%%' % (100.0 * cvec_counts1.nnz / (cvec_counts1.shape[0] * cvec_counts1.shape[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<7600x1098 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 30709 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformer1 = TfidfTransformer()\n",
    "transformed_weights1 = transformer.fit_transform(cvec_counts1)\n",
    "transformed_weights1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3, ..., 4, 1, 4], dtype=int64)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = nb.predict(transformed_weights1)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1501,  145,  159,   95],\n",
       "       [ 180, 1594,   58,   68],\n",
       "       [ 205,   69, 1373,  253],\n",
       "       [ 228,  107,  251, 1314]], dtype=int64)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(df1[\"Class\"], preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7607894736842106"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(df1[\"Class\"], preds, normalize=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
